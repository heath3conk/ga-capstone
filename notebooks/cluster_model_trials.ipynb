{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(modeling);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178265, 8023)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags_df = pd.read_parquet(\"data/generated_data/ingr_dummies.parquet\")\n",
    "flags_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44566, 8023)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_flags = flags_df.sample(frac=0.25, replace=False)\n",
    "sample_flags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_params = {\n",
    "    \"clusters\": range(5, 31, 5),\n",
    "    \"max_iter\": [300, 500]\n",
    "}\n",
    "\n",
    "dbscan_params = {\n",
    "    \"eps\": [0.1, 0.25, 0.5, 1.0, 1.25],\n",
    "    \"algorithm\": [\"auto\", \"kd_tree\"]\n",
    "}\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_5c_300i score = 0.025359556961519467\n",
      "kmeans_5c_500i score = 0.025359556961519467\n",
      "kmeans_10c_300i score = 0.01024073806683298\n",
      "kmeans_10c_500i score = 0.01024073806683298\n",
      "kmeans_15c_300i score = 0.012603195125328414\n",
      "kmeans_15c_500i score = 0.012603195125328414\n",
      "kmeans_20c_300i score = 0.006635561539243761\n",
      "kmeans_20c_500i score = 0.006635561539243761\n",
      "kmeans_25c_300i score = 0.00571858492315883\n",
      "kmeans_25c_500i score = 0.00571858492315883\n",
      "kmeans_30c_300i score = 0.007765257017801726\n",
      "kmeans_30c_500i score = 0.007765257017801726\n"
     ]
    }
   ],
   "source": [
    "kmeans_models = {}\n",
    "\n",
    "for cluster in kmeans_params[\"clusters\"]:\n",
    "    for max_i in kmeans_params[\"max_iter\"]:\n",
    "        model_name = f\"kmeans_{cluster}c_{max_i}i\"\n",
    "        details = {}\n",
    "        details[\"clusters\"] = cluster\n",
    "        details[\"max_iter\"] = max_i\n",
    "        km = KMeans(n_clusters=cluster, max_iter=max_i, n_init=\"auto\", random_state=42)\n",
    "        km.fit(sample_flags)\n",
    "        \n",
    "        sil_score = silhouette_score(sample_flags, km.labels_)\n",
    "        print(f\"{model_name} score = {sil_score}\")\n",
    "        details[\"score\"] = sil_score\n",
    "        details[\"inertia\"] = km.inertia_\n",
    "        \n",
    "        kmeans_models[model_name] = details\n",
    "        \n",
    "        with open(f\"models/{model_name}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(km, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan_0.1e_autoa score = -0.1137818994288678\n",
      "dbscan_0.1e_kd_treea score = -0.1137818994288678\n",
      "dbscan_0.25e_autoa score = -0.1137818994288678\n",
      "dbscan_0.25e_kd_treea score = -0.1137818994288678\n",
      "dbscan_0.5e_autoa score = -0.1137818994288678\n",
      "dbscan_0.5e_kd_treea score = -0.1137818994288678\n",
      "dbscan_1.0e_autoa score = -0.2008541704716405\n",
      "dbscan_1.0e_kd_treea score = -0.2008541704716405\n",
      "dbscan_1.25e_autoa score = -0.2008541704716405\n",
      "dbscan_1.25e_kd_treea score = -0.2008541704716405\n"
     ]
    }
   ],
   "source": [
    "dbscan_models = {}\n",
    "\n",
    "for eps in dbscan_params[\"eps\"]:\n",
    "    for algo in dbscan_params[\"algorithm\"]:\n",
    "        model_name = f\"dbscan_{eps}e_{algo}a\"\n",
    "        details = {}\n",
    "        details[\"eps\"] = eps\n",
    "        details[\"algorithm\"] = algo\n",
    "        dbscan = DBSCAN(eps=eps, algorithm=algo, n_jobs=-1)\n",
    "        dbscan.fit(sample_flags)\n",
    "        \n",
    "        sil_score = silhouette_score(sample_flags, dbscan.labels_)\n",
    "        print(f\"{model_name} score = {sil_score}\")\n",
    "        details[\"score\"] = sil_score\n",
    "        \n",
    "        dbscan_models[model_name] = details\n",
    "        \n",
    "        with open(f\"models/{model_name}\", \"wb\") as f:\n",
    "            pickle.dump(dbscan, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_35c_default_i score = 0.008281905915136617\n",
      "kmeans_40c_default_i score = 0.007494932185157251\n",
      "kmeans_45c_default_i score = 0.007244433685604815\n",
      "kmeans_50c_default_i score = 0.0076677207469152\n",
      "kmeans_55c_default_i score = 0.004070570047512586\n",
      "kmeans_60c_default_i score = 0.005761999899310619\n",
      "kmeans_65c_default_i score = 0.0065947546451767345\n",
      "kmeans_70c_default_i score = 0.005518304051742554\n",
      "kmeans_75c_default_i score = 0.0054834518212471895\n",
      "kmeans_80c_default_i score = 0.005751633972537051\n",
      "kmeans_85c_default_i score = 0.005776518868208993\n",
      "kmeans_90c_default_i score = 0.005115344110135365\n",
      "kmeans_95c_default_i score = 0.00500923247561521\n",
      "kmeans_100c_default_i score = 0.005285331211656954\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(35, 101, 5):\n",
    "    max_i = \"default_\"\n",
    "    model_name = f\"kmeans_{cluster}c_{max_i}i\"\n",
    "    details = {}\n",
    "    details[\"clusters\"] = cluster\n",
    "    details[\"max_iter\"] = max_i\n",
    "    km = KMeans(n_clusters=cluster, n_init=\"auto\", random_state=42)\n",
    "    km.fit(sample_flags)\n",
    "    \n",
    "    sil_score = silhouette_score(sample_flags, km.labels_)\n",
    "    print(f\"{model_name} score = {sil_score}\")\n",
    "    details[\"score\"] = sil_score\n",
    "    details[\"inertia\"] = km.inertia_\n",
    "    \n",
    "    kmeans_models[model_name] = details\n",
    "    \n",
    "    with open(f\"models/{model_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(km, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan_0.0001e_2p score = -0.1137818994288678\n",
      "dbscan_0.0001e_3p score = -0.1137818994288678\n",
      "dbscan_0.001e_2p score = -0.1137818994288678\n",
      "dbscan_0.001e_3p score = -0.1137818994288678\n",
      "dbscan_0.01e_2p score = -0.1137818994288678\n",
      "dbscan_0.01e_3p score = -0.1137818994288678\n"
     ]
    }
   ],
   "source": [
    "dbscan_eps = [0.0001, 0.001, 0.01]\n",
    "powers = [2, 3]\n",
    "\n",
    "for eps in dbscan_eps:\n",
    "    for power in powers:\n",
    "        model_name = f\"dbscan_{eps}e_{power}p\"\n",
    "        details = {}\n",
    "        details[\"eps\"] = eps\n",
    "        details[\"power\"] = power\n",
    "        dbscan = DBSCAN(eps=eps, p=power, n_jobs=-1)\n",
    "        dbscan.fit(sample_flags)\n",
    "        \n",
    "        sil_score = silhouette_score(sample_flags, dbscan.labels_)\n",
    "        print(f\"{model_name} score = {sil_score}\")\n",
    "        details[\"score\"] = sil_score\n",
    "        \n",
    "        dbscan_models[model_name] = details\n",
    "        \n",
    "        with open(f\"models/{model_name}\", \"wb\") as f:\n",
    "            pickle.dump(dbscan, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## filter for main dishes only\n",
    "- the full recipe database has all kinds of recipes so it's not too surprising that these models have been unimpressive\n",
    "- let's see if filtering the recipes to just \"main course\" will improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"data/kaggle_food_dot_com/RAW_recipes.csv\")\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1            a bit different  breakfast pizza   31490       30   \n",
       "2                   all in the kitchen  chili  112140      130   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['60-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'cuisine', 'preparation', 'occasion', 'north-american', 'side-dishes', 'vegetables', 'mexican', 'easy', 'fall', 'holiday-event', 'vegetarian', 'winter', 'dietary', 'christmas', 'seasonal', 'squash']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder that this is a list wrapped in a string\n",
    "raw[\"tags\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['60-minutes-or-less',\n",
       " 'time-to-make',\n",
       " 'course',\n",
       " 'main-ingredient',\n",
       " 'cuisine',\n",
       " 'preparation',\n",
       " 'occasion',\n",
       " 'north-american',\n",
       " 'side-dishes',\n",
       " 'vegetables',\n",
       " 'mexican',\n",
       " 'easy',\n",
       " 'fall',\n",
       " 'holiday-event',\n",
       " 'vegetarian',\n",
       " 'winter',\n",
       " 'dietary',\n",
       " 'christmas',\n",
       " 'seasonal',\n",
       " 'squash']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex for the win!!\n",
    "re.findall(r\"\\b[\\w+-?]+\", raw[\"tags\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [60-minutes-or-less, time-to-make, course, mai...\n",
       "1    [30-minutes-or-less, time-to-make, course, mai...\n",
       "2    [time-to-make, course, preparation, main-dish,...\n",
       "3    [60-minutes-or-less, time-to-make, course, mai...\n",
       "4    [weeknight, time-to-make, course, main-ingredi...\n",
       "Name: tag_list, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tags_to_list(tag_list):\n",
    "    return re.findall(r\"\\b[\\w+-?]+\", tag_list)\n",
    "\n",
    "raw[\"tag_list\"] = raw[\"tags\"].apply(tags_to_list)\n",
    "raw[\"tag_list\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = raw[\"tag_list\"].explode().unique()\n",
    "\n",
    "# getting an error trying to write these tags to a file: TypeError: write() argument must be str, not float\n",
    "# also need a `\\n` between each element so the file is readable\n",
    "tags = [ f\"{tag}\\n\" for tag in tags if type(tag) == str]\n",
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to get a good look at these tags so I know what to filter on\n",
    "f = open(\"data/generated_data/tags.txt\", \"a\")  # from https://www.w3schools.com/python/ref_file_writelines.asp\n",
    "f.writelines(tags)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(15, 24), match='main-dish'>\n",
      "<re.Match object; span=(0, 6), match='dinner'>\n",
      "<re.Match object; span=(0, 9), match='main-dish'>\n"
     ]
    }
   ],
   "source": [
    "# filtering for main course tags should include: [\"*-main-dish-*\", \"main-dish\", \"dinner-party\"] (searched tags for \"main\" and \"dinner\")\n",
    "test_tags = [\"middle-eastern-main-dish\", \"dinner-party\", \"main-dish-chicken\", \"pasta\"]\n",
    "\n",
    "for _ in test_tags:\n",
    "    matches = re.search(r\"main-dish|dinner\", _)\n",
    "    if matches != None:\n",
    "        print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_main(tag_list):\n",
    "    matches = re.search(r\"main-dish|dinner\", \" \".join(tag_list))\n",
    "    return 1 if matches != None else 0\n",
    "\n",
    "raw[\"main_course\"] = raw[\"tag_list\"].apply(flag_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96201"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(raw[\"main_course\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>main_course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "      <td>[30-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "      <td>[time-to-make, course, preparation, main-dish,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
       "      <td>this is a super easy, great tasting, make ahea...</td>\n",
       "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aww  marinated olives</td>\n",
       "      <td>25274</td>\n",
       "      <td>15</td>\n",
       "      <td>21730</td>\n",
       "      <td>2002-04-14</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['toast the fennel seeds and lightly crush the...</td>\n",
       "      <td>my italian mil was thoroughly impressed by my ...</td>\n",
       "      <td>['fennel seeds', 'green olives', 'ripe olives'...</td>\n",
       "      <td>9</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>backyard style  barbecued ribs</td>\n",
       "      <td>67888</td>\n",
       "      <td>120</td>\n",
       "      <td>10404</td>\n",
       "      <td>2003-07-30</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['in a medium saucepan combine all the ingredi...</td>\n",
       "      <td>this recipe is posted by request and was origi...</td>\n",
       "      <td>['pork spareribs', 'soy sauce', 'fresh garlic'...</td>\n",
       "      <td>22</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name      id  minutes  contributor_id  \\\n",
       "1  a bit different  breakfast pizza   31490       30           26278   \n",
       "2         all in the kitchen  chili  112140      130          196586   \n",
       "3                alouette  potatoes   59389       45           68585   \n",
       "6             aww  marinated olives   25274       15           21730   \n",
       "7    backyard style  barbecued ribs   67888      120           10404   \n",
       "\n",
       "    submitted                                               tags  \\\n",
       "1  2002-06-17  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  2005-02-25  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "3  2003-04-14  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "6  2002-04-14  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "7  2003-07-30  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "\n",
       "                                        nutrition  n_steps  \\\n",
       "1       [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2      [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "3       [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "6        [380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0]        4   \n",
       "7  [1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0]       10   \n",
       "\n",
       "                                               steps  \\\n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "3  ['place potatoes in a large pot of lightly sal...   \n",
       "6  ['toast the fennel seeds and lightly crush the...   \n",
       "7  ['in a medium saucepan combine all the ingredi...   \n",
       "\n",
       "                                         description  \\\n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "3  this is a super easy, great tasting, make ahea...   \n",
       "6  my italian mil was thoroughly impressed by my ...   \n",
       "7  this recipe is posted by request and was origi...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \\\n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6   \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13   \n",
       "3  ['spreadable cheese with garlic and herbs', 'n...             11   \n",
       "6  ['fennel seeds', 'green olives', 'ripe olives'...              9   \n",
       "7  ['pork spareribs', 'soy sauce', 'fresh garlic'...             22   \n",
       "\n",
       "                                            tag_list  main_course  \n",
       "1  [30-minutes-or-less, time-to-make, course, mai...            1  \n",
       "2  [time-to-make, course, preparation, main-dish,...            1  \n",
       "3  [60-minutes-or-less, time-to-make, course, mai...            1  \n",
       "6  [15-minutes-or-less, time-to-make, course, mai...            1  \n",
       "7  [weeknight, time-to-make, course, main-ingredi...            1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mains = raw.loc[raw[\"main_course\"] == 1]\n",
    "mains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96201"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_course_ids = list(mains[\"id\"])\n",
    "len(main_course_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(main_course_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pull in the processed recipes to match the recipe ids to this filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>i</th>\n",
       "      <th>name_tokens</th>\n",
       "      <th>ingredient_tokens</th>\n",
       "      <th>steps_tokens</th>\n",
       "      <th>techniques</th>\n",
       "      <th>calorie_level</th>\n",
       "      <th>ingredient_ids</th>\n",
       "      <th>ingr_ints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424415</td>\n",
       "      <td>23</td>\n",
       "      <td>[40480, 37229, 2911, 1019, 249, 6878, 6878, 28...</td>\n",
       "      <td>[[2911, 1019, 249, 6878], [1353], [6953], [153...</td>\n",
       "      <td>[40480, 40482, 21662, 481, 6878, 500, 246, 161...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[389, 7655, 6270, 1527, 3406]</td>\n",
       "      <td>[389, 7655, 6270, 1527, 3406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146223</td>\n",
       "      <td>96900</td>\n",
       "      <td>[40480, 18376, 7056, 246, 1531, 2032, 40481]</td>\n",
       "      <td>[[17918], [25916], [2507, 6444], [8467, 1179],...</td>\n",
       "      <td>[40480, 40482, 729, 2525, 10906, 485, 43, 8393...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...</td>\n",
       "      <td>[2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312329</td>\n",
       "      <td>120056</td>\n",
       "      <td>[40480, 21044, 16954, 8294, 556, 10837, 40481]</td>\n",
       "      <td>[[5867, 24176], [1353], [6953], [1301, 11332],...</td>\n",
       "      <td>[40480, 40482, 8240, 481, 24176, 296, 1353, 66...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...</td>\n",
       "      <td>[1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       i                                        name_tokens  \\\n",
       "0  424415      23  [40480, 37229, 2911, 1019, 249, 6878, 6878, 28...   \n",
       "1  146223   96900       [40480, 18376, 7056, 246, 1531, 2032, 40481]   \n",
       "2  312329  120056     [40480, 21044, 16954, 8294, 556, 10837, 40481]   \n",
       "\n",
       "                                   ingredient_tokens  \\\n",
       "0  [[2911, 1019, 249, 6878], [1353], [6953], [153...   \n",
       "1  [[17918], [25916], [2507, 6444], [8467, 1179],...   \n",
       "2  [[5867, 24176], [1353], [6953], [1301, 11332],...   \n",
       "\n",
       "                                        steps_tokens  \\\n",
       "0  [40480, 40482, 21662, 481, 6878, 500, 246, 161...   \n",
       "1  [40480, 40482, 729, 2525, 10906, 485, 43, 8393...   \n",
       "2  [40480, 40482, 8240, 481, 24176, 296, 1353, 66...   \n",
       "\n",
       "                                          techniques  calorie_level  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...              0   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...              1   \n",
       "\n",
       "                                      ingredient_ids  \\\n",
       "0                      [389, 7655, 6270, 1527, 3406]   \n",
       "1  [2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...   \n",
       "2  [1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...   \n",
       "\n",
       "                                           ingr_ints  \n",
       "0                      [389, 7655, 6270, 1527, 3406]  \n",
       "1  [2683, 4969, 800, 5298, 840, 2499, 6632, 7022,...  \n",
       "2  [1257, 7655, 6270, 590, 5024, 1119, 4883, 6696...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_df = pd.read_parquet(\"data/generated_data/processed_recipes.parquet\")\n",
    "proc_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(proc_df[\"id\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_mains = proc_df.loc[proc_df[\"id\"].isin(main_course_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75297, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_mains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6863"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients = proc_mains[\"ingr_ints\"].explode().unique()\n",
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- main course has 6,863 ingredients; the \"ingr_map\" has 8,023 ingredients, seems reasonable that this filtered list would have about 85% of those\n",
    "- dummify these recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75297, 6863)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "for id_col in ingredients:\n",
    "    col = []\n",
    "    for recipe_row in range(0, proc_mains.shape[0]):\n",
    "        flag = 1 if id_col in proc_mains[\"ingr_ints\"].iloc[recipe_row] else 0\n",
    "        col.append(flag)\n",
    "    cols.append(pd.Series(col))\n",
    "    \n",
    "flag_proc_df = pd.concat(cols, axis=1)\n",
    "flag_proc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I need to keep the recipe id with the flagged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_proc_df[\"recipe_id\"] = proc_mains[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heathercait/anaconda3/envs/capstone/lib/python3.12/site-packages/pandas/io/parquet.py:189: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/generated_data/main_dish_dummies.parquet\"\n",
    "flag_proc_df.to_parquet(file_name, engine=\"pyarrow\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## mysterious nulls in the \"recipe_id\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43339"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_proc_df[\"recipe_id\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- huh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_mains.shape[0] == flag_proc_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_mains[\"id\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there are no nulls in the un-dummified data and 43,339 (57%!) nulls in the dummified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/pxzljrp530ddx9cxpl80jslh0000gn/T/ipykernel_47478/3445753008.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  flag_proc_df.iloc[idx][\"recipe_id\"] = proc_mains.iloc[idx][\"id\"]\n"
     ]
    }
   ],
   "source": [
    "# I don't know why adding that column in a normal way is giving me nulls but I don't have time to figure it out\n",
    "for idx in range(proc_mains.shape[0]):\n",
    "    flag_proc_df.iloc[idx][\"recipe_id\"] = proc_mains.iloc[idx][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43339"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_proc_df[\"recipe_id\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- yup, still all those nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_ids = [ f\"{id}\\n\" for id in flag_proc_df[\"recipe_id\"] ]\n",
    "f = open(\"data/generated_data/ids.txt\", \"a\")  # from https://www.w3schools.com/python/ref_file_writelines.asp\n",
    "f.writelines(suspect_ids)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_ids = [ f\"{id}\\n\" for id in proc_mains[\"id\"] ]\n",
    "f = open(\"data/generated_data/orig_ids.txt\", \"a\")\n",
    "f.writelines(orig_ids)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- okay I still don't know why this is happening but those two files are...interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_proc_df[\"recipe_id\"] = [int(id) for id in proc_mains[\"id\"]]\n",
    "flag_proc_df[\"recipe_id\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I'm sure there's some dumb pandas reason why I had to do it that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heathercait/anaconda3/envs/capstone/lib/python3.12/site-packages/pandas/io/parquet.py:189: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/generated_data/main_dish_dummies.parquet\"\n",
    "flag_proc_df.to_parquet(file_name, engine=\"pyarrow\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this warning is actually about the COLUMN names and not the row types but I'm glad it came up earlier because I hadn't even thought to check for nulls in those recipe ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## kmeans with main-dish recipes only\n",
    "- please be better, please be better, please be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_5c_mains_all_mains score = 0.02611545207525439\n",
      "kmeans_12c_mains_all_mains score = 0.014283476656228896\n",
      "kmeans_19c_mains_all_mains score = 0.012512314175224897\n",
      "kmeans_26c_mains_all_mains score = 0.008327280580775554\n",
      "kmeans_33c_mains_all_mains score = 0.008020459279035021\n",
      "kmeans_40c_mains_all_mains score = 0.006950586773818742\n",
      "kmeans_47c_mains_all_mains score = 0.005277396017073416\n"
     ]
    }
   ],
   "source": [
    "new_model_details = pd.DataFrame()\n",
    "\n",
    "kmeans_mains = modeling.try_kmeans_models(cluster_range=range(5, 50, 7), name_modifier=\"all_mains\", \n",
    "                                          data_df=flag_proc_df.drop(columns=[\"recipe_id\"]), models_df=new_model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clusters</th>\n",
       "      <th>score</th>\n",
       "      <th>inertia</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>636096.272441</td>\n",
       "      <td>kmeans_5c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>12</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>607286.457808</td>\n",
       "      <td>kmeans_12c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>19</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>593800.245345</td>\n",
       "      <td>kmeans_19c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>26</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>585401.726760</td>\n",
       "      <td>kmeans_26c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>33</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>579045.612712</td>\n",
       "      <td>kmeans_33c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>574295.436875</td>\n",
       "      <td>kmeans_40c_mains_all_mains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>47</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>568123.103745</td>\n",
       "      <td>kmeans_47c_mains_all_mains</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type  clusters     score        inertia                        name\n",
       "0     kmeans         5  0.026115  636096.272441   kmeans_5c_mains_all_mains\n",
       "1     kmeans        12  0.014283  607286.457808  kmeans_12c_mains_all_mains\n",
       "2     kmeans        19  0.012512  593800.245345  kmeans_19c_mains_all_mains\n",
       "3     kmeans        26  0.008327  585401.726760  kmeans_26c_mains_all_mains\n",
       "4     kmeans        33  0.008020  579045.612712  kmeans_33c_mains_all_mains\n",
       "5     kmeans        40  0.006951  574295.436875  kmeans_40c_mains_all_mains\n",
       "6     kmeans        47  0.005277  568123.103745  kmeans_47c_mains_all_mains"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_mains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan_0.0001e_mains score = -0.11207505922147183\n",
      "dbscan_0.001e_mains score = -0.11207505922147183\n",
      "dbscan_0.01e_mains score = -0.11207505922147183\n",
      "dbscan_0.1e_mains score = -0.11207505922147183\n",
      "dbscan_0.25e_mains score = -0.11207505922147183\n",
      "dbscan_0.5e_mains score = -0.11207505922147183\n",
      "dbscan_1.0e_mains score = -0.18771775409269265\n",
      "dbscan_1.25e_mains score = -0.18771775409269265\n"
     ]
    }
   ],
   "source": [
    "dbscan_eps = [0.0001, 0.001, 0.01, 0.1, 0.25, 0.5, 1.0, 1.25]\n",
    "dbscan_model_details = []\n",
    "\n",
    "for eps in dbscan_eps:\n",
    "    trial_details = {}\n",
    "    trial_details[\"eps\"] = eps\n",
    "    dbscan = DBSCAN(eps=eps, n_jobs=-1)\n",
    "    dbscan.fit(flag_proc_df)\n",
    "    \n",
    "    sil_score = silhouette_score(flag_proc_df, dbscan.labels_)\n",
    "    trial_details[\"score\"] = sil_score\n",
    "    \n",
    "    dbscan_model_details.append(trial_details)\n",
    "    \n",
    "    model_name = f\"dbscan_{eps}e_mains\"\n",
    "    print(f\"{model_name} score = {sil_score}\")\n",
    "    \n",
    "    with open(f\"models/main_course_recipes_models/{model_name}\", \"wb\") as f:\n",
    "        pickle.dump(dbscan, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_models = pd.DataFrame.from_dict(dbscan_model_details)\n",
    "dbscan_models.to_parquet(\"data/generated_data/filtered_dbscan_model_trials.parquet\", engine=\"pyarrow\", compression= \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## filter most frequent ingredients\n",
    "- maybe 6,863 ingredients is too many\n",
    "- let's try with fewer ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75297, 6863)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_proc_df = pd.read_parquet(\"data/generated_data/main_dish_dummies.parquet\")\n",
    "flag_proc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only ingredients that show up in more than 5 recipes from: https://www.geeksforgeeks.org/pandas-filter-a-dataframe-by-the-sum-of-rows-or-columns/\n",
    "df = flag_proc_df.loc[:, flag_proc_df.sum(axis=0) > 5]  # that 5 is totally arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75297, 3526)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_5c_mains_half_features score = 0.029910841250235503\n",
      "kmeans_12c_mains_half_features score = 0.013916367465081743\n",
      "kmeans_19c_mains_half_features score = 0.010370923066061931\n",
      "kmeans_26c_mains_half_features score = 0.003903981046639545\n",
      "kmeans_33c_mains_half_features score = 0.005742282437713488\n",
      "kmeans_40c_mains_half_features score = 0.0016878940560285907\n",
      "kmeans_47c_mains_half_features score = 0.0035814081637385695\n"
     ]
    }
   ],
   "source": [
    "updated_kmeans_results = modeling.try_kmeans_models(cluster_range=range(5,50,7), name_modifier=\"half_features\", \n",
    "                                                    data_df=df.drop(columns=[\"recipe_id\"]), models_df=kmeans_mains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- that was no better than the results of all the main dishes\n",
    "- I also don't know why my `range(5,55,7)` was stepping by 5 instead of 7?? \n",
    "    - figure out that it was because I hadn't reimported modeling.py after changing the loop in that function from the hard-coded range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PCA\n",
    "- instead of me deciding how many features to include, let's let sklearn actually figure out what's important\n",
    "- this is from lesson 2.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per docs, \"randomized\" solver is used for input data larger than 500x500, \n",
    "#  I'm specifying it here so I remember that later\n",
    "#  first ran this cell when df did not include the recipe_id column\n",
    "pca = PCA(svd_solver=\"randomized\", random_state=42)\n",
    "pca.fit(df)\n",
    "trained = pca.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance (first 20 components): [0.034 0.031 0.025 0.021 0.018 0.015 0.014 0.013 0.012 0.011 0.011 0.01\n",
      " 0.009 0.009 0.009 0.009 0.008 0.008 0.008 0.007]\n",
      "\n",
      "Cumulative explained variance (first 30 components): [0.034 0.065 0.09  0.111 0.129 0.144 0.159 0.172 0.184 0.195 0.206 0.216\n",
      " 0.225 0.235 0.244 0.252 0.261 0.268 0.276 0.283 0.291 0.298 0.304 0.311\n",
      " 0.317 0.324 0.33  0.336 0.341 0.346]\n"
     ]
    }
   ],
   "source": [
    "# Pull the explained variance attribute.\n",
    "# shows how much of the variance is explained by each PCA, these values will always add up to 1\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance (first 20 components): {np.round(var_exp[:20], 3)}\\n\")\n",
    "\n",
    "# Generate the cumulative explained variance.\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Cumulative explained variance (first 30 components): {np.round(cum_var_exp[:30], 3)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 827 features out of 3525 explain 90% of the variance\n"
     ]
    }
   ],
   "source": [
    "# how many features do I want to include? found this at: https://www.geeksforgeeks.org/python-get-the-index-of-first-element-greater-than-k/\n",
    "i_90 = next(x for x, val in enumerate(cum_var_exp)if val > 0.9)\n",
    "print(f\"the first {i_90-1} features out of {len(cum_var_exp)} explain 90% of the variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_90 = PCA(svd_solver=\"randomized\", random_state=42, n_components=827)\n",
    "pca_90.fit(df.drop(columns=[\"recipe_id\"]))\n",
    "trained = pca_90.transform(df.drop(columns=[\"recipe_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_5c_mains_pca_90 score = 0.026829644684107607\n",
      "kmeans_12c_mains_pca_90 score = 0.011722777805553905\n",
      "kmeans_19c_mains_pca_90 score = 0.004633226682016011\n"
     ]
    }
   ],
   "source": [
    "pca_kmeans_results = modeling.try_kmeans_models(cluster_range=range(5, 20, 7), name_modifier=\"pca_90\", \n",
    "                                                data_df=trained, models_df=updated_kmeans_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_results_file = \"data/generated_data/filtered_kmeans_model_trials.parquet\"\n",
    "pca_kmeans_results.to_parquet(kmeans_results_file, engine=\"pyarrow\", compression= \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         kmeans_5c_mains_all_mains\n",
       "1        kmeans_12c_mains_all_mains\n",
       "2        kmeans_19c_mains_all_mains\n",
       "3        kmeans_26c_mains_all_mains\n",
       "4        kmeans_33c_mains_all_mains\n",
       "5        kmeans_40c_mains_all_mains\n",
       "6        kmeans_47c_mains_all_mains\n",
       "0     kmeans_5c_mains_half_features\n",
       "1    kmeans_12c_mains_half_features\n",
       "2    kmeans_19c_mains_half_features\n",
       "3    kmeans_26c_mains_half_features\n",
       "4    kmeans_33c_mains_half_features\n",
       "5    kmeans_40c_mains_half_features\n",
       "6    kmeans_47c_mains_half_features\n",
       "0            kmeans_5c_mains_pca_90\n",
       "1           kmeans_12c_mains_pca_90\n",
       "2           kmeans_19c_mains_pca_90\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_kmeans_results[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AgglomerativeClustering\n",
    "- suggestion from Sumit to use hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# starting with all default values & fitting on the non-PCA subset of features\n",
    "agg_c = AgglomerativeClustering()\n",
    "agg_c.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data after kernel crashed\n",
    "flag_proc_df = pd.read_parquet(\"data/generated_data/main_dish_dummies.parquet\")\n",
    "\n",
    "# we'll try this on the smaller, PCA data set\n",
    "pca_90 = PCA(svd_solver=\"randomized\", random_state=42, n_components=827)\n",
    "pca_90.fit(flag_proc_df)\n",
    "trained = pca_90.transform(flag_proc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# starting with all default values & fitting on the PCA subset of features\n",
    "agg_c = AgglomerativeClustering()\n",
    "agg_c.fit(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [the article](https://towardsdatascience.com/a-practical-introduction-to-hierarchical-clustering-from-scikit-learn-ffaf8ee2670c) I read about AgglomerativeClustering says that you can't use the silhouette score to evaluate the model\n",
    "- according to that article, you'd have to rely on your domain knowledge to say if the model is generating anything useful\n",
    "- I'm going to calculate it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(trained, agg_c.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
